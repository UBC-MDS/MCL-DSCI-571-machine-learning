---
params:
  dynamictitle: "module5_01"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module5/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
import glob
from sklearn.pipeline import Pipeline, make_pipeline
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz

from IPython.display import HTML, display
from PIL import Image, ImageFile

from plot_classifier import plot_classifier


# Classifiers and regressors
from sklearn.dummy import DummyClassifier, DummyRegressor

# Preprocessing and pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics.pairwise import euclidean_distances

# train test split and cross validation
from sklearn.model_selection import cross_val_score, cross_validate, train_test_split
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, MinMaxScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier


pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

path = "../../../../static/module5/"
```


type: slides

# The importance of preprocessing

Notes: <br>

---

<br>
<br>


### So far ...

- Models: Decision trees, ùëò-NNs, SVMs with RBF kernel.
- Fundamentals: Train-validation-test split, cross-validation, the fundamental tradeoff, the golden rule.

<br>
<br>

### Now 

**Preprocessing**: Transforming input data into a format a machine learning model can use and understand. 



Notes: 

So far we have seen:    

- Three ML models (decision trees, ùëò-NNs, SVMs with RBF kernel)
- ML fundamentals (train-validation-test split, cross-validation, the fundamental tradeoff, the golden rule)

Are we ready to do machine learning on real-world datasets?
- Very often real-world datasets need to be transformed or ***preprocessed***  before we use them to build ML models. 
  
   

---

## Basketball dataset

```{python}
bball_df = pd.read_csv('data/bball.csv')
bball_df.head()
```

```{python}
bball_df = bball_df[(bball_df['position'] =='G') | (bball_df['position'] =='F')]
X = bball_df[['weight', 'height', 'salary']]
y =bball_df["position"]
X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.20, random_state=123)
```

```{python}
X_train.head()
```


Notes: 

In module 3, we used a portion of the basketball dataset to predict a players position using `DecisionTreeClassifier`. 

Can we use ùëò-NN classifier for this task? 

Intuition: To predict whether a particular player is a pointguard ('G') or a forward ('F') (query point) 

- Find the players that are closest to the query point
- Let them vote on the target
- Take the majority vote as the target for the query point

---

### Geometric view of tabular data and dimensions 

```{python}
dummy = DummyClassifier(strategy="most_frequent")
scores = cross_validate(dummy, X_train, y_train, return_train_score=True)
print('Mean validation score', scores['test_score'].mean().round(2))
```

```{python}
knn = KNeighborsClassifier()
scores = cross_validate(knn, X_train, y_train, return_train_score=True)
print('Mean validation score', scores['test_score'].mean().round(2))
```


Notes: 

First, let's see what scores we get if we simply predict the most occuring position in the dataset using our dummy classifier. 

Now if we build our ùëò-NN classifier we determine that it gets even *worse* scores! Why? 


---

```{python}
two_players = X_train.sample(2, random_state=42)
two_players
```
```{python}
euclidean_distances(two_players)
```
```{python}
two_players_subset = two_players[["salary"]]
two_players_subset
```
```{python}
euclidean_distances(two_players_subset)
```



Notes: 

Let's have a look at just 2 players as calculate the distance between them.

We can see the distance between player 285 and 236 is 117133.00184683. 

What happens if we only consider the `salary` column though? 

It looks like we get almost the same distance! 

The distance is completely dominated by the the features with larger values. 

The features with smaller values are being ignored. 

Does it matter? 

- Yes! Scale is based on how data was collected. 
- Features on a smaller scale can be highly informative and there is no good reason to ignore them.
- We want our model to be robust and not sensitive to the scale. 
  
Was this a problem for decision trees?

- No. In decision trees we ask questions on one feature at a time. 


So what do we do about this? 

Well, we have to scale the columns they they are all using a similar range of values! 

Luckily Sklearn has tools called ***transformers** for this. 

---

## Transformers: Scaling example


```{python}
from sklearn.preprocessing import StandardScaler
```
<br>

```{python}
scaler = StandardScaler()    # Create feature transformer object
scaler.fit(X_train) # fitting the transformer on the train split 
X_train_scaled = scaler.transform(X_train) # transforming the train split
X_test_scaled = scaler.transform(X_test) # transforming the test split
pd.DataFrame(X_train_scaled, columns = X_train.columns).head()
```


Notes: 

One form of preprocessing we can do is ***scaling*** we will talk about this is more details to come but for now just take a look at the tools we are using. 

We'll be using  on `scikit-learn`'s [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html), which is a `transformer`.  

 For now, try to only focus on the syntax.
 
 We'll talk about scaling in a bit.
 
1. Create feature transformer object. this is done in a similar way to how we create a model. 
2. Fitting the transformer on the train split 
3. Transform the train split using `.transform()`
4. Then tranform the test split. 

- `sklearn` uses `fit` and `transform` paradigms for feature transformations. (In model building it was `fit` and `predict` or `score`)
- We `fit` the transformer on the train split and then `transform` the train split as well as the test split. 
- We apply the same transformations on the test split. 


---

## Scikit learn's *predict* vs *transform* 


```python
model.fit(X_train, y_train)
X_train_predictions = model.predict(X_train)
X_test_predictions = model.predict(X_test)
```


```python
transformer.fit(X_train, [y_train])
X_train_transformed = transformer.transform(X_train)
X_test_transformed = transformer.transform(X_test)
```  

```python
transformer.fit_transform(X_train)
```


Notes:

Suppose we have a named `model` which is either a  classification or regression model. 

We can compare it with  `transformer` which is a transformer used to change the input representation like to scales numeric features.

You can pass `y_train` in `fit` but it's usually ignored. It allows you to pass it just to be consistent with usual usage of `sklearn`'s `fit` method.   

You can also carry out fitting and transforming in one call using `fit_transform`, but be mindful to use it only on the train split and **not** on the test split. 

---

```{python}
knn_unscaled = KNeighborsClassifier();
knn_unscaled.fit(X_train, y_train)
print('Train score: ', (knn_unscaled.score(X_train, y_train).round(2)))
print('Test score: ', (knn_unscaled.score(X_test, y_test).round(2)))
```

```{python}
knn_scaled = KNeighborsClassifier();
knn_scaled.fit(X_train_scaled, y_train)
print('Train score: ', (knn_scaled.score(X_train_scaled, y_train).round(2)))
print('Test score: ', (knn_scaled.score(X_test_scaled, y_test).round(2)))
```


Notes: 

Do you expect `DummyClassifier` results to change after scaling the data? 

Let's check whether scaling makes any difference for ùëò-NNs. 

The scores with scaled data are better compared to the unscaled data in case of ùëò-NNs.

We am not carrying out cross-validation here for a reason that that we'll look into soon. 

We are being a bit sloppy here by using the test set several times for teaching purposes. 

But when you build an ML models, you should only assess the test set once.  

---


# Let‚Äôs apply what we learned!

Notes: <br>
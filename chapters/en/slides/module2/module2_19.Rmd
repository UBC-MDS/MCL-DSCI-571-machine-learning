---
params:
  dynamictitle: "module2_19"
title: "`r params$dynamictitle`"
output: 
  md_document:
    variant: gfm
---


```{r setup, include=FALSE}
## DO NOT FORGET TO CHANGE THIS ACCORDINGLY 
library(rmarkdown)
# MAke sure you are updating your title 
knitr::opts_chunk$set(echo = TRUE,
                      base.dir = ".", 
                      base.url = "/",
                      fig.path = paste("../../../../static/module2/", params$dynamictitle,"/", sep = ""))

knitr_opts <- knitr_options( opts_knit = NULL,
                             opts_chunk = NULL,
                             knit_hooks = NULL,
                             opts_hooks = NULL,
                             opts_template = NULL)
md_document_custom <- md_document(variant = "gfm")
output_format(knitr = knitr_opts,
              pandoc = NULL,
              base_format = md_document_custom)
library(reticulate)

```


```{python include=FALSE}
import pandas as pd
import numpy as np
import altair as alt
from altair_saver import save
import glob
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline, make_pipeline
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LinearRegression, LogisticRegression
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz

from IPython.display import HTML, display
from PIL import Image, ImageFile

from plot_classifier import plot_classifier
pd.set_option('display.width', 350)

np.set_printoptions(linewidth=400)

pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 15)

path = "../../../../static/module2/"
from display_tree import display_tree
```


type: slides

# Generalization

Notes: <br>

---

### Visualizing model complexity using decision boundaries

```{python}
classification_df = pd.read_csv("data/quiz2-grade-toy-classification.csv")
classification_df
```




Notes: 

In the last lecture, we learned about decision boundaries. 

We saw that we could visualize the splitting of decision trees using these boundaries. 

Let's use our familiar quiz2 data back again to build on our decision boundary knowledge.



--- 

```{python}
X = classification_df.drop(columns=["quiz2"])
y = classification_df["quiz2"]
```

```{python}
X_subset = X[["lab4", "quiz1"]]
X_subset.head()
```




Notes: 

If we subset our data and look at the 2 features from data named `lab4` and `quiz1` we can see the values the decision tree is splitting on. 

----

```{python}
depth = 1
model = DecisionTreeClassifier(max_depth=depth)
model.fit(X_subset, y);
model.score(X_subset, y)
```

```{python include=FALSE}
display_tree(X_subset.columns, model, "../../../../static/module2/module2_18a")
```

<center><img src="/module2/module2_18a.png"  width = "30%" alt="404 image" /></center>

Notes: 

In the following decision tree model, this decision boundary is created by asking one question.



---

<center><img src="/module2/module2_18a.png"  width = "25%" alt="404 image" /></center>

```{python  echo=FALSE,  fig.width = 13, fig.height = 9,  out.width = '65%', fig.align='center'}
plt.figure(figsize=(4, 4))
plot_classifier(X_subset.to_numpy(), y.to_numpy(), model, ticks=True, lims=(70,101,70,101))
plt.xticks(fontsize= 20);
plt.yticks(fontsize= 20);
plt.xlabel('lab4', fontsize=20);
plt.ylabel('quiz1', fontsize=20);
plt.title("Decision tree with depth = %d" % (depth), fontsize=24)
```

Notes: 

Here the red region corresponds to the "not A+" class and the blue region corresponds to the "A+" class. 

We can see there is a line separating the red region and the blue region which is called the **decision boundary** of the model.


---

```{python}
depth = 2
model = DecisionTreeClassifier(max_depth=depth)
model.fit(X_subset, y);
model.score(X_subset, y)
```

```{python include=FALSE}
display_tree(X_subset.columns, model, "../../../../static/module2/module2_18b")
```

<center><img src="/module2/module2_18b.png"  width = "30%" alt="404 image" /></center>

Notes: 

Let's see what happens to our decision boundary when we change for different tree heights.

In the following model, this decision boundaries are created by asking two questions. 


---


<center><img src="/module2/module2_18b.png"  width = "25%" alt="404 image" /></center>

```{python  echo=FALSE,    fig.width = 13, fig.height = 9,  out.width = '65%', fig.align='center'}
plt.figure(figsize=(4, 4))
plot_classifier(X_subset.to_numpy(), y.to_numpy(), model, ticks=True, lims=(70,101,70,101))
plt.xticks(fontsize= 20);
plt.yticks(fontsize= 20);
plt.xlabel('lab4', fontsize=20);
plt.ylabel('quiz1', fontsize=20);
plt.title("Decision tree with depth = %d" % (depth), fontsize=24)
```


---


```{python }
depth = 4
model = DecisionTreeClassifier(max_depth=depth)
model.fit(X_subset, y);
model.score(X_subset, y)
```

```{python include=FALSE}
display_tree(X_subset.columns, model, "../../../../static/module2/module2_18c")
```

<center><img src="/module2/module2_18c.png"  width = "40%" alt="404 image" /></center>


Notes: 

In the next model, this decision boundaries are created by asking three questions. 


---

```{python}
model.score(X_subset, y)
```

```{python echo=FALSE, fig.width = 13, fig.height = 9,  out.width = '70%', fig.align='center'}
plt.figure(figsize=(4, 4))
plot_classifier(X_subset.to_numpy(), y.to_numpy(), model, ticks=True, lims=(70,101,70,101))
plt.xticks(fontsize= 20);
plt.yticks(fontsize= 20);
plt.xlabel('lab4', fontsize=20);
plt.ylabel('quiz1', fontsize=20);
plt.title("Decision tree with depth = %d" % (depth), fontsize=24)
```

Notes: 


---

```{python}
depth = 10
model = DecisionTreeClassifier(max_depth=depth)
model.fit(X_subset, y);
model.score(X_subset, y)
```

```{python include=FALSE}
display_tree(X_subset.columns, model, "../../../../static/module2/module2_18d")
```

<center><img src="/module2/module2_18d.png"  width = "45%" alt="404 image" /></center>


Notes: 

For this last model, the decision boundaries are created by asking 10 questions.


---

```{python}
model.score(X_subset, y)
```

```{python  echo=FALSE,  fig.width = 13, fig.height = 9,  out.width = '65%', fig.align='center'}
plt.figure(figsize=(4, 4))
plot_classifier(X_subset.to_numpy(), y.to_numpy(), model, ticks=True, lims=(70,101,70,101))
plt.xticks(fontsize= 20);
plt.yticks(fontsize= 20);
plt.xlabel('lab4', fontsize=20);
plt.ylabel('quiz1', fontsize=20);
plt.title("Decision tree with depth = %d" % (depth), fontsize=24)
```

Notes: 

Our model has 0% error!!
But it's also becoming more and more specific and sensitive to the training data.
Is it good or bad?


---


## Fundamental goal of machine learning 


<center><img src="/module2/generalization-train.png" width = "50%" alt="404 image" /></center>

Notes: 

The fundamental goal of machine learning is **to generalize beyond what we see in the training examples**.


Example: Imagine that a learner sees the following images and corresponding labels.



---

### Generalizing to unseen data


<center><img src="/module2/generalization-predict.png" width = "100%" alt="404 image" /></center>

Notes: 

Now the learner is presented with new images (1 to 4) for prediction. 

What prediction would you expect for each image?   

We want the learner to be able to generalize beyond what it has seen in the training data, but these new examples should be representative of the training data. 

For instance, is it fair to expect the learner to label image 4 correctly?


---


## Training score versus Generalization score 

- Given a model in ML, people usually talk about two kinds of accuracies (scores):

1. Accuracy on the training data
    
2. Accuracy on the entire distribution of data


Notes:   

This is where the model accuracy comes in. 

People usually talk about two kinds of accuracies (scores) in machine learning:

1. Accuracy on the training data
    
2. Accuracy on the entire distribution of data

We are interested in the accuracy on the entire distribution, but we do not have access to the entire distribution!

What do we do? 

We will cover this, in the next module. 
    
---

# Letâ€™s apply what we learned!

Notes: <br>
## Introduction to Machine Learning 

### Module 1

- Be able to explain motivation to study machine learning;
- Be able to differentiate between supervised and unsupervised learning
- Differentiate between classification and regression problems
- Explain machine learning terminology such as features, targets, training, and error
- Use DummyClassifier/ Dummy Regressor as a baseline for machine learning problems
- Explain the fit and predict paradigm and use score method of ML models


### Module 2

- Broadly describe how decision trees make predictions
- Use DecisionTreeClassifier and DecisionTreeRegressor to build decision trees using scikit-learn
- Explain the fit and predict paradigm and use score method of ML models;
- Explain the concept of decision boundaries;
- Explain the different between parameters and hyperparameters.
- Explain how decision boundaries change with max_depth;
- Explain the concept of generalization;
- Split a dataset into train and test sets using train_test_split function;

### Module 3 

- Explain the difference between train, validation, test, and "deployment" data;
- Identify the difference between training error, validation error, and test error;
- Explain cross-validation and use cross_val_score and cross_validate to calculate cross-validation error;
- Explain overfitting, underfitting, and the fundamental tradeoff;
- State the golden rule and identify the scenarios when it's violated.

### Module 4 

- Explain the notion of similarity-based algorithms;
- Broadly describe how KNNs use distances
- Discuss the effect of using a small/large value of the hyperparameter $K$ when using the KNN algorithm.
- Explain the general idea of SVM with RBF kernel.
- Discuss the difference between parametric and non-parametric machine learning models.

### Module 5 
- Imputation 
- Scaling 
- Pipeline 

- Identify when to implement feature transformations such as imputation, scaling, and one-hot encoding in a machine learning model development pipeline;
- Use sklearn for applying them on your dataset;
- Discuss golden rule in the context of feature transformations;
- Use sklearn.pipeline.Pipeline to build a preliminary machine learning pipeline.

## Module 6 
- Categorical variables -> one-hot, Ordinal encoding 
- ColumnTransformer



### Module 7

- Explain the need for hyperparameter optimization
- Carry out hyperparameter optimization using sklearn's GridSearchCV and RandomizedSearchCV
- Explain optimization bias
- Identify and reason when to trust and not trust reported accuracies
- precision and recall 
- Data inbalance 
- MAPE? 

## Module 8 

- Text classification? 
- Explain the general intuition behind linear models
- Explain the predict paradigm of linear models
- Use scikit-learn's LogisticRegression classifier
- Use fit, predict, predict_proba
- Use coef_ to interpret the model weights
- Explain the advantages and limitations of linear classifiers

